#!/usr/bin/env python
"""
Comprehensive test runner for intelligent scheduling tests.

This script runs all tests related to intelligent scheduling and provides
a detailed report of the results.
"""
import os
import sys
import django

# Setup Django
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'phantom.settings')
django.setup()

from django.test.utils import get_runner
from django.conf import settings
from django.core.management import call_command


def print_header(text):
    """Print a formatted header."""
    print("\n" + "=" * 80)
    print(f"  {text}")
    print("=" * 80 + "\n")


def run_tests():
    """Run all intelligent scheduling tests."""
    print_header("PHANTOM AI INTELLIGENT SCHEDULING TEST SUITE")
    
    print("This test suite verifies that the Phantom AI agent can:")
    print("  âœ“ Understand implicit user needs")
    print("  âœ“ Create events automatically")
    print("  âœ“ Update/reshuffle events based on priorities")
    print("  âœ“ Delete low-priority events when necessary")
    print("  âœ“ Maintain schedule integrity")
    print("  âœ“ Use intelligent defaults")
    print("  âœ“ Handle conflicts proactively")
    print()
    
    # Get the test runner
    TestRunner = get_runner(settings)
    test_runner = TestRunner(verbosity=2, interactive=False, keepdb=False)
    
    # Test modules to run
    test_modules = [
        'ai_agent.test_intelligent_scheduling',
        'ai_agent.test_chat_endpoint_integration',
    ]
    
    print_header("RUNNING TESTS")
    
    total_failures = 0
    
    for module in test_modules:
        print(f"\n{'â”€' * 80}")
        print(f"Running: {module}")
        print('â”€' * 80)
        
        failures = test_runner.run_tests([module])
        total_failures += failures
    
    # Print summary
    print_header("TEST SUMMARY")
    
    if total_failures == 0:
        print("âœ… ALL TESTS PASSED!")
        print()
        print("The Phantom AI agent is working correctly:")
        print("  â€¢ Implicit understanding: âœ“")
        print("  â€¢ Automatic event creation: âœ“")
        print("  â€¢ Priority-based scheduling: âœ“")
        print("  â€¢ Conflict resolution: âœ“")
        print("  â€¢ Context awareness: âœ“")
        print("  â€¢ Intelligent defaults: âœ“")
        print()
        print("The agent is ready for production use! ğŸ‰")
        return 0
    else:
        print(f"âŒ {total_failures} TEST(S) FAILED")
        print()
        print("Please review the failures above and fix the issues.")
        print("Common issues:")
        print("  â€¢ Missing dependencies (check requirements.txt)")
        print("  â€¢ Database not migrated (run: python manage.py migrate)")
        print("  â€¢ Categories not populated (run: python manage.py populate_categories)")
        print("  â€¢ Gemini API key not configured (check .env file)")
        return 1


def main():
    """Main entry point."""
    try:
        # Check if database is ready
        print("Checking database...")
        call_command('check', '--database', 'default')
        print("âœ“ Database is ready\n")
        
        # Run migrations if needed
        print("Ensuring migrations are up to date...")
        call_command('migrate', '--no-input')
        print("âœ“ Migrations complete\n")
        
        # Run tests
        exit_code = run_tests()
        
        sys.exit(exit_code)
        
    except Exception as e:
        print(f"\nâŒ Error running tests: {str(e)}")
        print("\nPlease ensure:")
        print("  1. Virtual environment is activated")
        print("  2. All dependencies are installed (pip install -r requirements.txt)")
        print("  3. Database is configured correctly")
        print("  4. .env file contains required settings")
        sys.exit(1)


if __name__ == '__main__':
    main()
